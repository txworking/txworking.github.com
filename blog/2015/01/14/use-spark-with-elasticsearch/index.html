
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>使用Spark对ElasticSearch进行读取 - Darcy Tang's Blog</title>
  <meta name="author" content="Darcy Tang">

  
  <meta name="description" content="ElasticSearch for Apache Hadoop是ES提供的工具库，让Hadoop、Pig、Hive等可以比较原生的方式去和ES交互。
目前提供了mapreduce、hive、pig、cascading、spark、storm的集成。 下面以Spark为例， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://txworking.github.io/blog/2015/01/14/use-spark-with-elasticsearch">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Darcy Tang's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Darcy Tang's Blog</a></h1>
  
    <h2>记录一点编程心得</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:txworking.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about-me">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">使用Spark对ElasticSearch进行读取</h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-14T17:22:00+08:00" pubdate data-updated="true">Jan 14<span>th</span>, 2015</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>ElasticSearch for Apache Hadoop是ES提供的工具库，让Hadoop、Pig、Hive等可以比较原生的方式去和ES交互。
目前提供了mapreduce、hive、pig、cascading、spark、storm的集成。</p>

<p>下面以Spark为例，演示如何利用这个工具库去读取ES记录</p>

<p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/hadoop/current/spark.html">官方指南</a></p>

<h2>安装</h2>

<p>我使用的是spark-shell交互式环境进行的测试，所以需要手动下载elasticsearch-hadoop的jar包。
在maven项目中可以通过添加</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>    <span class="nt">&lt;groupId&gt;</span>org.elasticsearch<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;artifactId&gt;</span>elasticsearch-hadoop<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;version&gt;</span>2.1.0.Beta3<span class="nt">&lt;/version&gt;</span>
</span><span class='line'><span class="nt">&lt;/dependency&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>这是包含了所有支持的jar包，也可以下载单独的spark支持包。</p>

<p>对于Spark，还需要下载Kryo，来替代Spark自带的序列化包。</p>

<p>最后elasticsearch-hadoop只支持Java 1.7以上版本，所以需要看看Java环境是否匹配。</p>

<p>启动spark-shell时，使用以下命令加载特定jar包</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>./bin/spark-shell -jars ./elasticsearch-hadoop-2.1.0.Beta3.jar;./kryo-3.0.0/jar
</span></code></pre></td></tr></table></div></figure>


<p>指定序列化工具</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>import com.esotericsoftware.kryo.KryoSerializable
</span><span class='line'>import org.apache.spark.SparkConf
</span><span class='line'>
</span><span class='line'>val conf = new SparkConf()
</span><span class='line'>conf.set(&quot;spark.serializer&quot;, classOf[KryoSerializer].getName)
</span></code></pre></td></tr></table></div></figure>


<h2>读取</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>import org.apache.hadoop.conf.Configuration
</span><span class='line'>import org.elasticsearch.hadoop.mr.EsInputFormat
</span><span class='line'>import org.apache.hadoop.io.Text
</span><span class='line'>import org.apache.hadoop.io.MapWritable
</span><span class='line'>
</span><span class='line'>val conf = new Configuration()
</span><span class='line'>conf.set(&quot;es.resource&quot;, &quot;highrisk/blacklist&quot;) //指定读取的索引名称
</span><span class='line'>conf.set(&quot;es.nodes&quot;, &quot;127.0.0.1&quot;)
</span><span class='line'>conf.set(&quot;es.query&quot;, &quot;?q=me*&quot;)  //使用query字符串对结果进行过滤
</span><span class='line'>val esRDD = sc.newHadoopRDD(conf, classOf[EsInputFormat[Text, MapWritable]],
</span><span class='line'>                                  classOf[Text], classOf[MapWritable]))
</span><span class='line'>val docCount = esRDD.count();
</span></code></pre></td></tr></table></div></figure>


<p>读取出来的记录为key-value形式，key为Text类型，value为MapWritable类型。
接下来就可以利用Spark对esRDD进行各种map、flatmap、reduceByKey的操作了。</p>

<h2>写入</h2>

<p>参考<a href="http://chenlinux.com/2014/09/04/spark-to-elasticsearch/">用Spark处理数据导入ElasticSearch</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>import org.apache.spark.SparkConf
</span><span class='line'>import org.elasticsearch.spark._
</span><span class='line'>
</span><span class='line'>val conf = new SparkConf()
</span><span class='line'>conf.set(&quot;es.index.auto.create&quot;, &quot;true&quot;)
</span><span class='line'>conf.set(&quot;es.nodes&quot;, &quot;127.0.0.1&quot;)
</span><span class='line'>
</span><span class='line'>val numbers = Map(&quot;one&quot; -&gt; 1, &quot;two&quot; -&gt; 2, &quot;three&quot; -&gt; 3)
</span><span class='line'>val airports = Map(&quot;OTP&quot; -&gt; &quot;Otopeni&quot;, &quot;SFO&quot; -&gt; &quot;San Fran&quot;)
</span><span class='line'>sc.makeRDD(Seq(numbers, airports)).saveToEs(&quot;spark/docs&quot;)
</span></code></pre></td></tr></table></div></figure>


<p>目前elasticsearch-hadoop对Spark的支持还比较简单，想要对记录进行过滤就只有通过query字符串或者全部读取后在Spark中过滤，对规模比较大的索引或者复杂的过滤查询不友好。</p>

<h2>配置</h2>

<p>主要的配置
* es.resource
* es.resource.read    默认与es.resource相同
* es.resource.write   默认与es.resource相同
* es.nodes 默认为localhost
* es.port  默认为9200
* es.query 默认为none</p>

<p>完整的请查看<a href="http://www.elasticsearch.org/guide/en/elasticsearch/hadoop/current/configuration.html">Configuration</a></p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Darcy Tang</span></span>

      








  


<time datetime="2015-01-14T17:22:00+08:00" pubdate data-updated="true">Jan 14<span>th</span>, 2015</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/elasticsearch/'>elasticsearch</a>, <a class='category' href='/blog/categories/spark/'>spark</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://txworking.github.io/blog/2015/01/14/use-spark-with-elasticsearch/" data-via="" data-counturl="http://txworking.github.io/blog/2015/01/14/use-spark-with-elasticsearch/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/01/02/angular-plus-springmvc/" title="Previous Post: AngularJS+SpringMVC构建应用">&laquo; AngularJS+SpringMVC构建应用</a>
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/01/14/use-spark-with-elasticsearch/">使用Spark对ElasticSearch进行读取</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/02/angular-plus-springmvc/">AngularJS+SpringMVC构建应用</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/02/ruby2-dot-0/">Ruby和Ruby2.0相关文章汇总</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/08/17/check-logfiles/">在Nagios中实时监控日志</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/08/a-bug-of-facter/">Facter在Windows上的一个小问题</a>
      </li>
    
  </ul>
</section>




  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Darcy Tang -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'darcytang';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://txworking.github.io/blog/2015/01/14/use-spark-with-elasticsearch/';
        var disqus_url = 'http://txworking.github.io/blog/2015/01/14/use-spark-with-elasticsearch/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
